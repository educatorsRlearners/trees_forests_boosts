{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame the Problem\n",
    "\n",
    "Predict who survived the sinking of *The Titanic*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Load the Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data \n",
    "\n",
    "*What about missing values?* \n",
    "\n",
    "XGBoost can handle them by [default](https://xgboost.readthedocs.io/en/stable/faq.html#how-to-deal-with-missing-values) but do this with care. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Evaluate the Model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install seaborn\n",
    "# %pip install xgboost\n",
    "# %pip install -U scikit-learn\n",
    "# %pip install graphviz\n",
    "\n",
    "# Restart your kernel \n",
    "\n",
    "\n",
    "#or \n",
    "\n",
    "# !pip install seaborn\n",
    "# !pip install xgboost\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install graphviz\n",
    "\n",
    "\n",
    "\n",
    "# Restart your kernel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['is_female'] = np.where(titanic['sex'] == 'female', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate a XGBClassifier \n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, random_state=RANDOM_STATE)\n",
    "\n",
    "# Inspect the parameters\n",
    "xgb_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['pclass', 'is_female', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "X = titanic.loc[:, keep]\n",
    "y = titanic.loc[:, 'survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Learning Curve\n",
    "evals_result = xgb_clf.evals_result()\n",
    "\n",
    "train_errors = evals_result['validation_0']['logloss']\n",
    "\n",
    "validation_errors = evals_result['validation_1']['logloss']\n",
    "\n",
    "df = pd.DataFrame([train_errors, validation_errors]).T\n",
    "\n",
    "df.columns = ['train', 'validation']\n",
    "\n",
    "df.index.name = 'round'\n",
    "\n",
    "df.plot(title='XGBoost Learning Curve', ylim=(0, 0.7), figsize=(12, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.survived.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split using sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.33, \n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_train, \n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), \n",
    "                      (X_test, y_test)],\n",
    "            verbose=10)\n",
    "\n",
    "preds = xgb_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times a feature appears in a tree\n",
    "xgb.plot_importance(xgb_clf, \n",
    "                    importance_type='weight', \n",
    "                    max_num_features=5,\n",
    "                    title='Feature Importance Based on Weight',);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "xgb.plot_tree(xgb_clf, num_trees=99, rankdir='LR', ax=ax);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The accuracy score for XGBClassifier is:', xgb_clf.score(X_test,y_test))\n",
    "\n",
    "cm_array = confusion_matrix(y_test, preds, labels=[0,1])\n",
    "\n",
    "\n",
    "label_names = ['did not survive', 'survived']\n",
    "\n",
    "df_cm = pd.DataFrame(cm_array, \n",
    "                     index=label_names, \n",
    "                     columns=label_names)\n",
    "\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', annot_kws={\"size\": 16}); # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average gain of splits for each feature?\n",
    "xgb.plot_importance(xgb_clf, \n",
    "                    importance_type='gain', \n",
    "                    max_num_features=5, \n",
    "                    title='Feature Importance Based on Gain');"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b21b5b969092a9065663de355da31a3d1f96950f5d68195abe9cea0aaca678f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('boosting': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
